---
title: Risker med artificiell intelligens
description: AI hotar vår demokrati, vår teknologi och vår art.
---

AI-system är en kraftfull teknik som i allt större utsträckning förändrar vår värld. Den kommer med fantastisk potential, men också med allvarliga risker, inklusive [existentiell risk](/xrisk).

## Nuvarande faror

### Falsk media, polarisering och hot mot demokratin
Mycket av vårt samhälle är baserat på tillit. Vi litar på att pengarna på vårt bankkonto är verkliga, att nyheterna vi läser är sanna, och att personerna som postar recensioner online existerar. AI-system är exceptionellt bra på att skapa falsk media. De kan skapa falska videor, falska ljud, falska texter och falska bilder. Dessa kapaciteter förbättras snabbt. För bara två år sedan skrattade vi åt de hemskt orealistiska Dall-E-bilderna, men nu har vi [deepfake-bilder som vinner fototävlingar](https://www.theguardian.com/technology/2023/apr/17/photographer-admits-prize-winning-image-was-ai-generated). 

Ett 10-sekunders ljudklipp eller en enda bild kan vara nog för att skapa en övertygande deepfake. Att skapa falska medier är inte nytt, men AI gör det mycket billigare och mycket mer realistiskt. En AI-genererad bild av en explosion orsakade [panikförsäljning på Wall Street](https://www.euronews.com/next/2023/05/23/fake-news-about-an-explosion-at-the-pentagon-spreads-on-verified-accounts-on-twitter).

Aktuella chattbotsmodeller från till exempel OpenAI kan skriva på ett sätt som är omöjligt att skilja från människor, men i en mycket snabbare takt och till en bråkdel av kostnaden. Vi kanske snart ser sociala medier översvämmas med falska diskussioner och åsikter, och falska nyhetsartiklar som är omöjliga att skilja från riktiga.

Detta leder till polarisering mellan olika grupper av människor som tror på olika informationskällor och narrativ och, genom att konsumera förvrängda representationer av vad som händer, eskalerar sina skillnader tills de kulminerar i våldsamma och antidemokratiska svar.

Ett stopp för frontlinjemodeller (vårt [förslag](/proposal)) skulle inte stoppa de modeller som används idag för att skapa falska medier, men det skulle kunna hjälpa till att förhindra framtida avancerade modeller. Dessutom skulle det lägga grunden för framtida reglering som syftar till att minska spridningen av falska media och andra specifika problem orsakade av AI. För att inte tala om att öka allmänhetens uppmärksamhet och medvetenhet om dessa faror och visa att vi kan påverka utvecklingen genom att göra våra röster hörda.

### Deepfakes och imitation
Falskt innehåll skapat med AI, till exempel så kallade deepfakes, kan inte bara stjäla kända personers identiteter och [skapa desinformation](https://time.com/6565446/biden-deepfake-audio/), utan de kan också imitera dig. Alla med foton, videor eller ljud av någon och tillräcklig kunskap kan skapa deepfakes av dessa personer och använda dessa för att begå bedrägerier, trakassera eller skapa sexuellt icke-konsensuellt material. Ungefär 96% av allt deepfake-innehåll är sexuellt material.

Som avsnittet om falska nyheter säger, skulle falska medier inte helt förhindras av vårt förslag, men de kunde minskas till viss del. En inte så liten del när man tar i beaktande att multimodala AI-system som chatbots har blivit väldigt populära, och vi skulle stoppa dem från att bli mer kapabla och populära, vilket kan inkludera system designade med färre filter och träningsbara med nya ansikten.

### Fördomar och diskriminering
AI-system tränas på data, och mycket av den data vi har är på något sätt partisk. Detta innebär att AI-system kommer att ärva samhällets fördomar. Ett klassiskt exempek utgörs av Amazons automatiserade rekryteringssystem [som ärvde en fördom mot kvinnor](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G).

Ett annat exempel utgörs av maskininlärningsbaserade beslutssystem i hälso- och sjukvård som underskattade symptomen hos svarta patienter och därigenom [minskade deras möjlighetger att få dekvat vård](https://www.science.org/doi/full/10.1126/science.aax2342). Partiska system som används inom brottsbekämpning, såsom prediktiva polissystem, kan leda till att specifika grupper blir måltavlor baserat på felaktiga grunder. Generativa AI-modeller kopierar inte bara fördomarna från deras träningsdata, [de förstärker dem](https://www.bloomberg.com/graphics/2023-generative-ai-bias/).
Dessa fördomar uppstår ofta utan att skaparna av AI-systemet är medvetna om dem.

<!-- ### Dataskydd
-->

### Jobbförlust, ekonomisk ojämlikhet och instabilitet
Under den industriella revolutionen förlorade många människor sina jobb till maskiner. Men nya (och ofta bättre) jobb skapades, och ekonomin växte. Den här gången kan saker och ting vara annorlunda.

AI ersätter inte bara våra muskler som ångmaskinen gjorde, den ersätter våra hjärnor. Vanliga människor kanske inte har något kvar att erbjuda ekonomin. Bildgenereringsmodeller (som är kraftigt tränade på upphovsrättsskyddat material från professionella konstnärer) påverkar redan [den kreativa industrin](https://cointelegraph.com/news/artists-face-a-choice-with-ai-adapt-or-become-obsolete).

Skribenter har [strejkat](https://www.newscientist.com/article/2373382-why-use-of-ai-is-a-major-sticking-point-in-the-ongoing-writers-strike/). Redan relativt tidiga system, som GPT-4 från OpenAI [klarade advokatexamen](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/), kan producera kvalitativt textinnehåll och kan skriva programmeringskod (återigen, delvis tränad på [upphovsrättsskyddat material](https://www.ischool.berkeley.edu/news/2023/new-research-prof-david-bamman-reveals-chatgpt-seems-be-trained-copyrighted-books)).

De som äger dessa AI-system kommer att kunna kapitalisera på dem, men de som förlorar sina jobb till dem kommer inte att göra det.
Det är svårt att förutsäga vilka jobb som kommer att ersättas först. AI-systemen skulle kunna gör dig arbetslös oavsett hur mycket tid, pengar och energi du har spenderat på att få den erfarenhet och kunskap som du har. Vårt samhälle är inte förberett för detta.

### Mental hälsa, beroende och avskildhet mellan människor
Sociala medier, videospel och annan programvara har redan använt AI-system för att maximera sin vinst medan de utnyttjar våra primathjärnor, vilket kan påverka vår mentala hälsa i processen. Överanvändning av bland annat sociala medier, kan isolera oss från varandra och leda till att vi fastnar i politiska, kulturella och sociala bubblor. De kan ses som en tidiga oavsiktliga och oväntade globala negativa konsekvenser som dessa teknologier kan medföra och hur komplicerat det kan vara att linjera dessa AI-baserade system med mänskliga värderingar.

Om dagens chatbots fortsätter att bli mer kapabla, skulle vi kunna blir alltför beroende av dem och ersätta  relationer (vare sig romantiska, sexuella eller platoniska) med dem. I detta avseende kan barn och ungdomar vara särskilt sårbara då de är i ett utvecklingsskede då AI-systemen kan påverka deras identitet och syn på världen. En paus av den aggressiva utecklingen och spridningen av de största och mest kapabla multifunktionella chatbottarna, som "perfekt" tillgodoser våra behov bör tas på allvar, särskilt i ett läge då vi inte förstår de långsiktiga konsekvenserna av dem.

### Maktkoncentration, krig och kapplöpning mot avgrunden
Beroendet av produkter och tjänster som lär sig av personlig data kan underminera vår egenmakt och isolera oss, vare sig det är avsiktligt eller inte. Och, i tillägg riskerar det att leda till en en ond cirkel med fler personer som använder systemen och delar sin data, som används av techföretagen för att vidareutveckla sina modeller, med följd att de tillskansar sig mer teknologisk och ekonomisk makt.  Om denna ekonomiska och teknologiska makt samlas hos från en handfull aktörer, kan det leda till en maktkoncentration som kan resultera i en massiv underminering av vårt självbestämmande, som individder, men också på sammhällelig och nationell nivå. Så det är avgörande att agera så snart som möjligt, innan tävlingsdynamiken som driver den aggresiva satsningen på att utveckla kraftfulla generellt intelligenta AI-system system leder till katastrofala utfall. Vi behöver agera och samarbeta internationell, eftersom det enda vinnande draget i detta konstiga spel är att inte spela, utan att pausa.

### Auktoritära regeringar
Auktoritära och totalitära regeringar kan också använda AI-teknologier för att utöva makt över sina territorier och befolkningar.
De kan kontrollera kommunikationskanaler eller upprätthålla sociala kredit- och massövervakningssystem som säkerställer att de behåller sin makt samtidigt som de kränker mänskliga rättigheter.

### Autonoma vapen
Företag säljer redan AI-drivna vapen till regeringar. Lanius bygger flygande drönare som autonomtidentifierar fiender och eliminerar dem. Palantirs AIP-system använder stora språkmodeller för att analysera slagfältsdata och komma med optimala strategier. Nationer och vapenföretag har insett att AI kommer att ha en enorm inverkan på att överträffa sina fiender.
Vi har gått in i en ny kapprustning, vilket skapar en dynamik att skynda på och ta genvägar.

Just nu har vi fortfarande människor i loopen för dessa vapen. Men, när kapaciteten hos dessa AI-system förbättras kommer det att bli mer och mer tryck att ge maskinerna makten att fatta beslut. När vi delegerar kontrollen över vapen till AI, kan fel och buggar få fruktansvärda konsekvenser. Den hastighet med vilken AI kan bearbeta information och fatta beslut kan orsaka att konflikter eskalerar på några minuter. En nyligen publicerad artikel konstaterar att "modeller tenderar att utveckla kapprustningsdynamik, vilket leder till större konflikter och i sällsynta fall till och med till användning av kärnvapen". Läs mer på stopkillerrobots.org

## Nära framtida faror

### Biologiska vapen
AI kan göra kunskap mer tillgänglig, vilket också inkluderar kunskap om hur man skapar biologiska vapen. Denna artikel visar hur en tidig modell som GPT-4 kunde bistå studenter utan vetenskaplig kunskap att skapa en pandemi-patogen:

På en timme föreslog chatbotarna fyra potentiella pandemi-patogener, förklarade hur de kan genereras från syntetiskt DNA med hjälp av omvänd genetik, försåg namnen på DNA-syntesföretag som troligen inte screenar beställningar, identifierade detaljerade protokoll och hur man felsöker dem, och rekommenderade att någon som saknar färdigheterna att utföra omvänd genetik engagerar en kärnanläggning eller ett kontraktsforskningsföretag.

Denna typ av kunskap har aldrig varit så tillgänglig, och vi har inte säkerhetsåtgärderna på plats för att hantera de potentiella konsekvenserna.

Dessutom kan vissa AI-modeller användas för att designa nya farliga patogener. En modell kallad MegaSyn designade 40 000 nya kemiska vapen/toxiska molekyler på en timme. Den revolutionära AlphaFold-modellen kan förutsäga strukturen av proteiner, vilket också är en dual-use technology. Att förutsäga proteinstrukturer kan användas för att lösa många av våra medicinska utmaningar, men också för att "upptäcka sjukdomsframkallande mutationer med hjälp av en individs genomsekvens". Forskare skapar nu till och med helt autonoma kemiska laboratorier, där AI-system själva kan syntetisera nya kemikalier. Ytterligare en grundläggande fara, är att kostnaden för att designa och använda biologiska vapen sänks med magnituder på grund av AI.
<!--Additionally, some AI models can be used to design completely new hazardous pathogens. A model called MegaSyn designed [40,000 new chemical weapons / toxic molecules in one hour](https://www.theverge.com/2022/3/17/22983197/ai-new-possible-chemical-weapons-generative-models-vx). The revolutionary AlphaFold model can predict the structure of proteins, which is also a [dual-use technology](https://unicri.it/sites/default/files/2021-12/21_dual_use.pdf). Predicting protein structures can be used to "discover disease-causing mutations using one individual’s genome sequence". Scientists are now even creating [fully autonomous chemical labs, where AI systems can synthesize new chemicals on their own](https://twitter.com/andrewwhite01/status/1670794000398184451). The fundamental danger is that the cost of designing and applying biological weapons is being lowered by orders of magnitude because of AI.-->

### Maktansamling och tyranni
Kraftfulla AI-modeller kan användas för att få mer makt. Denna återkopplingsloop kan leda till att ett fåtal företag och regeringar kan tillskansa sig enorm makt. Kontroll över tusentals autonoma generellt högintelligenta system skulle kunna användas för att opinionsbilding som bygger på propaganda och desinformation, manipulation av den ekonomiska marknaden, skapa och driva konflikter och till och med krig. I händerna på auktoritära regeringar skulle systemen kunna användas för att tysta kritiska röster och behålla sin makt.
<!--Dystopian social credit systems based on mass surveillance + people and action recognition could be created with today's AI so a pause wouldn't help and we shouldn't write about it-->

### Datorvirus och Cybersäkerhet 
Praktiskt taget allt vi gör idag är på något sätt beroende av digitala system som består av hård- och mjukvara. Dessa system används för betaltjänster, kalendrar, kommunikation, bokningssystem och i de flesta färdmededl, som våra tåg, bilar, båtar och flyg. Moderna AI-system kan analysera och skriva programvara. De kan hitta sårbarheter i programvara, och de kan användas för att utnyttja dem, och när kapaciteten växer kommer också möjligheterna att använda dem i illvilliga och kriminella syftem.

Mycket potenta datorvirus har alltid varit extremt svåra att skapa, men AI kan förändra detta. Istället för att behöva anlita ett team av skickliga säkerhetsexperter/hackare för att identifiera sårbarheter, kan personer idag använda lättillgängliga AI-system. Naturligtvis kan AI också hjälpa till med cyberförsvar, och det är oklart på vilken sida fördelen ligger. [Läs mer om AI och cybersäkerhetsrisker](/cybersecurity-risks)
<!--### Computer viruses and cybersecurity attacks
Virtually everything we do nowadays is in some way dependent on computers. We pay for our groceries, plan our days, contact our loved ones and even drive our cars with computers. Modern AI systems can analyze and write software. They [can find vulnerabilities](https://betterprogramming.pub/i-used-gpt-3-to-find-213-security-vulnerabilities-in-a-single-codebase-cc3870ba9411) in software, and [they could be used to exploit them](https://blog.checkpoint.com/2023/03/15/check-point-research-conducts-initial-security-analysis-of-chatgpt4-highlighting-potential-scenarios-for-accelerated-cybercrime/). As AI capabilities grow, so will the capabilities of the exploits they can create. Highly potent computer viruses have always been extremely hard to create, but AI could change that. Instead of having to hire a team of skilled security experts/hackers to find zero-day exploits, you could just use a far cheaper AI to do it for you. Of course, AI could also help with cyberdefense, and it is unclear on which side the advantage lies. [Read more about AI and cybersecurity risks](/cybersecurity-risks)-->

### Existentiell risk
Många AI-forskare varnar för att generellt kraftfull intelligent autonom AI kan leda till katastrofala följder för oss människor. Mycket intelligenta saker är mycket kraftfulla. Om vi bygger en maskin som är mycket mer intelligent än människor, måste vi vara säkra på att den vill samma sak som vi vill. Detta visar sig dock vara mycket svårt. Detta kallas anpassningsproblemet. Om vi misslyckas med att lösa det i tid, kan vi sluta med superintelligenta maskiner som inte bryr sig om vårt välbefinnande. Vi skulle introducera en ny art på planeten som kan överlista oss och överträffa oss. [Läs mer om x-risk](/xrisk)

### Mänsklig maktlöshet
Även om vi lyckas skapa  AI-system som vi kan kontrollera, kan vi förlora vår makt att fatta viktiga beslut, allteftersom system implementeras inom institutioner eller blir populärt i vardagen. Dessa system skulle få mer input från andra system än från människor, och om vi inte kan samordna oss tillräckligt snabbt, eller saknar nödvändig kunskap om hur dessa system fungerar, kan vi hamna i ett läge där vi inte har kontroll över vår framtid.

Vi skulle bli en civilisation där dessa system optimerar för olika mål, i vilken det inte finns ingen klar riktning för vart allt är på väg. Den tekniska kunskapen som krävs för att modifiera dessa system kan saknas från början eller gå förlorad över tid, när vi blir mer och mer beroende av teknik, och tekniken blir mer komplex. Systemen kan uppnå sina mål, men dessa mål kanske inte helt baseras på de värderingar de förväntades ha. Detta problem finns till viss del redan idag, men i relation till kraftfull autonom AI kan kan konsekvenserna bli avsevärt mer negativa. 

# Vad kan vi göra?
För alla problem som diskuterats ovan ökar risken när kapaciteten hos AI-systemen förbättras. Detta innebär att det säkraste att göra nu är att sakta ner. Vi behöver pausa utvecklingen av mer kraftfulla AI-system tills vi har listat ut hur vi ska hantera riskerna. Se vårt [förslag](/proposal) för mer detaljer.

<!--### Digital medvetenhet
När AI fortsätter att utvecklas kan framtida system bli otroligt sofistikerade och replikera neurala strukturer och funktioner som liknar den mänskliga hjärnan. Denna ökade komplexitet kan leda till framväxande egenskaper som subjektivitet och/eller medvetande, så att dessa AI skulle förtjäna moraliska överväganden och behandlas väl. De skulle vara som "digitala människor". Problemet är att, med tanke på vår nuvarande brist på kunskap om medvetandet och neurala nätverks natur, kommer vi inte att kunna avgöra om vissa AI skulle ha någon typ av upplevelse och vad kvaliteten på dessa upplevelser skulle bero på. Om AI fortsätter att produceras endast med deras kapacitet i åtanke, genom en process vi inte helt förstår, kommer människor fortsätta att använda dem som verktyg utan att förstå vad deras önskningar kan vara, och de kan faktiskt förslava digitala människor.
<!--As AI continues to advance, future systems may become incredibly sophisticated, replicating neural structures and functions that are more akin to the human brain. This increased complexity might lead to emergent properties like AI subjectivity and/or consciousness, which would make them deserving of moral considerations. The problem is that, given our present lack of knowledge about consciousness and the nature of neural networks, we won't have a way to determine whether some AIs would have any type of experience and what the quality of those experiences would depend on. If the AIs continue to be produced with only their capabilities in mind, through a process we don't fully understand, people will keep using them as tools ignoring what their desires could be, and that they could be actually enslaving "digital people".-->

<!--Risker med inlåst lidande
Det är möjligt att när automatisering på högre nivåer börjar ske, oavsett om det finns en eller flera kraftfulla AI, skulle värderingarna hos dessa system inte kunna ändras, och automatiseringen skulle fortsätta till universums slut, genom alla nåbara galaxer. De värsta scenarierna som dessa AI kan skapa skulle inte vara mänsklig utrotning, utan oundvikliga dystopier som skulle sträcka sig genom hela den tidsrymden.

Möjliga inlåsta dystopier med mycket lidande kallas S-risker och inkluderar världar där kännande varelser är förslavade och tvingas göra hemska saker. Dessa varelser kan vara människor, djur, digitala människor eller någon annan utomjordisk art som systemet kan hitta i kosmos. Med tanke på hur svårt vi tror att det är att helt lösa anpassningsproblemet, hur dåligt vi människor ibland behandlar varandra, hur illa vi behandlar de flesta djur, och hur vi behandlar nuvarande AI, kanske en framtid som denna inte är så osannolik som vi skulle vilja.

### S-risker
Det är inte bara så att värdeinlåsning kan göra att vi misslyckas med att uppnå den bästa sortens världar, utan det kan också leda till att vi hamnar i dystopier värre än utrotning som kan sträcka sig över all rumtid. Möjliga inlåsta dystopier med mycket lidande kallas _S-risker_(från engelskans suffering risk) och inkluderar världar där kännande varelser är förslavade och tvingade att göra hemska saker. Dessa varelser kan vara människor, djur, digitala människor eller någon annan främmande art som AI:n kan hitta i kosmos. Med tanke på hur svårt vi tycker att det är att lösa allians helt och hållet, hur illa vi människor behandlar varandra ibland, hur illa vi behandlar de flesta djur och hur vi behandlar nuvarande AI:er, verkar en framtid som denna inte så osannolik som vi hoppas.-->
